{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def data_extract_class(data_file):\n",
    "    \"\"\"\n",
    "    :param data_file:   csv file containing light sequences, heavy sequences and their tm50 values.\n",
    "    :return:            lists of light sequences, heavy sequences and tm50 values.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(data_file)\n",
    "    df.rename(columns={'VL': 'Light'}, inplace=True)\n",
    "    df.rename(columns={'VH': 'Heavy'}, inplace=True)\n",
    "    df.rename(columns={\"Fab Tm by DSF (°C)\": 'Temp'}, inplace=True)\n",
    "\n",
    "    light_seq = df['Light'].values.tolist()\n",
    "    heavy_seq = df['Heavy'].values.tolist()\n",
    "    temp = df['Temp'].values.tolist()\n",
    "    bin = df['bin'].values.tolist()\n",
    "\n",
    "\n",
    "    return light_seq, heavy_seq, temp, bin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bert_data_512 = \"../data/combined_bert_df.csv\"\n",
    "bert_data_60 = \"../data/combined_datasets_60.csv\"\n",
    "df = pd.read_csv(bert_data_60)\n",
    "\n",
    "light, heavy, temp, bin = data_extract_class('../data/combined_datasets_class.csv')\n",
    "\n",
    "X = df\n",
    "y = bin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=200, num=20)]\n",
    "max_features = [1.0, 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params = {'n_estimators': n_estimators,\n",
    "          'max_features': max_features,\n",
    "          'max_depth': [20],\n",
    "          'min_samples_split': [5],\n",
    "          'min_samples_leaf': min_samples_leaf,\n",
    "          'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "def rf_class(X, y, params, iters, cv_num):\n",
    "    \"\"\"\n",
    "    Random Forest Classifier\n",
    "    :param X: features\n",
    "    :param y: labels\n",
    "    :param params: hyperparameters\n",
    "    :param iters: number of iterations\n",
    "    :param cv_num: number of cross validations\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 28)\n",
    "\n",
    "    # random forest classifier\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    # randomized search\n",
    "    rf_random = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=iters, cv=cv_num, verbose=2, n_jobs=-1)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    best = rf_random.best_estimator_\n",
    "\n",
    "    best.fit(X_train, y_train)\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    target_names = ['<70', '70 - 75', '>75']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    # print MCC\n",
    "    print(\"MCC: \",(matthews_corrcoef(y_test, y_pred)))\n",
    "\n",
    "    # return best estimator\n",
    "    return rf_random.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toon_\\.virtualenvs\\AntibodyFvTm50Predictor\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 240 is smaller than n_iter=1000. Running 240 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <70       0.91      0.91      0.91        11\n",
      "     70 - 75       0.60      0.75      0.67         4\n",
      "         >75       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.84      0.78      0.79        18\n",
      "weighted avg       0.86      0.83      0.84        18\n",
      "\n",
      "MCC:  0.698908763644629\n",
      "CPU times: total: 2.95 s\n",
      "Wall time: 53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = rf_class(X, y, params, 1000, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(max_depth=20, max_features=1.0, min_samples_split=5,\n                       n_estimators=105)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, max_features=1.0, min_samples_split=5,\n                       n_estimators=105)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, max_features=1.0, min_samples_split=5,\n                       n_estimators=105)</pre></div></div></div></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['../models/08082023_rf_classifier_model.joblib']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, \"../models/08082023_rf_classifier_model.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <70       0.80      0.73      0.76        11\n",
      "     70 - 75       0.40      0.50      0.44         4\n",
      "         >75       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.73      0.74      0.74        18\n",
      "weighted avg       0.74      0.72      0.73        18\n",
      "\n",
      "MCC:  0.516579067117774\n",
      "CPU times: total: 1.3 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = rf_class(X, y, params, 100, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <70       0.80      0.73      0.76        11\n",
      "     70 - 75       0.33      0.50      0.40         4\n",
      "         >75       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.71      0.63      0.65        18\n",
      "weighted avg       0.73      0.67      0.69        18\n",
      "\n",
      "MCC:  0.4199471900174085\n",
      "CPU times: total: 1.61 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = rf_class(X, y, params, 100, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "gbt_params = {'n_estimators': n_estimators,\n",
    "          'max_features': ['sqrt'],\n",
    "          'max_depth': [10],\n",
    "          'min_samples_split': min_samples_split ,\n",
    "          'min_samples_leaf': [2]\n",
    "          }\n",
    "\n",
    "def gbt_class(X, y, params, iters, cv_num):\n",
    "    \"\"\"\n",
    "    Random Forest Classifier\n",
    "    :param X: features\n",
    "    :param y: labels\n",
    "    :param params: hyperparameters\n",
    "    :param iters: number of iterations\n",
    "    :param cv_num: number of cross validations\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 28)\n",
    "\n",
    "    # gradient boosted classifier\n",
    "    model = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "    # randomized search\n",
    "    gbt_random = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=iters, cv=cv_num, verbose=2, n_jobs=-1)\n",
    "    gbt_random.fit(X_train, y_train)\n",
    "\n",
    "    best = gbt_random.best_estimator_\n",
    "\n",
    "    best.fit(X_train, y_train)\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    target_names = ['<70', '70 - 75', '>75']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    # print MCC\n",
    "    print(\"MCC: \",(matthews_corrcoef(y_test, y_pred)))\n",
    "\n",
    "    # return best estimator\n",
    "    return gbt_random.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toon_\\.virtualenvs\\AntibodyFvTm50Predictor\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 60 is smaller than n_iter=100. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <70       0.83      0.91      0.87        11\n",
      "     70 - 75       0.67      0.50      0.57         4\n",
      "         >75       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.83      0.80      0.81        18\n",
      "weighted avg       0.82      0.83      0.83        18\n",
      "\n",
      "MCC:  0.688998622004134\n",
      "CPU times: total: 1 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbt_classifier = gbt_class(X, y, gbt_params, 100, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n                           min_samples_leaf=2, min_samples_split=10,\n                           n_estimators=48)",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=10, max_features=&#x27;sqrt&#x27;,\n                           min_samples_leaf=2, min_samples_split=10,\n                           n_estimators=48)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=10, max_features=&#x27;sqrt&#x27;,\n                           min_samples_leaf=2, min_samples_split=10,\n                           n_estimators=48)</pre></div></div></div></div></div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "['../08082024_gbt_classifier_model']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbt_classifier,\"../08082024_gbt_classifier_model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=200, num=20)]\n",
    "max_features = [1.0, 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "svm_params = {'C': uniform(loc=0, scale=1000), 'gamma': ['scale', 'auto'] + list(np.logspace(-5, 2, 10))}\n",
    "\n",
    "# svm classifier\n",
    "def svm_classifier(X, y, params, iters, cv_num):\n",
    "    \"\"\"\n",
    "    SVM Classifier\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 28)\n",
    "\n",
    "    # svm classifier\n",
    "    model = SVC()\n",
    "\n",
    "    # randomized search\n",
    "    svm_random = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=iters, cv=cv_num, verbose=2, n_jobs=-1)\n",
    "    svm_random.fit(X_train, y_train)\n",
    "\n",
    "    best = svm_random.best_estimator_\n",
    "\n",
    "    best.fit(X_train, y_train)\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    target_names = ['<70', '70 - 75', '>75']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    # print MCC\n",
    "    print(\"MCC: \",(matthews_corrcoef(y_test, y_pred)))\n",
    "\n",
    "    # return best estimator\n",
    "    return svm_random.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <70       0.73      0.73      0.73        11\n",
      "     70 - 75       0.40      0.50      0.44         4\n",
      "         >75       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.54      0.52      0.52        18\n",
      "weighted avg       0.62      0.61      0.61        18\n",
      "\n",
      "MCC:  0.28979143858435835\n"
     ]
    }
   ],
   "source": [
    "svm_class = svm_classifier(X, y, svm_params, 1000, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['../models/08082025_svm_classifier_model.joblib']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_class, \"../models/08082025_svm_classifier_model.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
